---
title: "Data filtering and manipulation"
author: "Shelley, Sangay and AC"
date: "02/02/2022"
output:
  pdf_document: default
  html_document: default
---
```{r}
# install.packages("knitr")
# install.packages("vegan")
# install.packages("ggplot2")
# install.packages("tidyverse")
```
*Objective:* To subset morphological data by including or excluding samples based on filters (e.g. list of characters, groupings, etc.)

*Description of script:* This is a two-step filtering processes for the downstream analysis with filtering process (1) based on the characters used and (2) based on the samples to include.

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "..")
# check and set WD for markdwon file, tools>Global options>Rmarkdown>Evaluate chunks in directory(project)
getwd()

library(cluster) #for hierarchical clustering
library(vegan) # NMDS and other statistics
library(ggplot2)
library(tidyverse)
library(GGally)
library(naniar)
```
Define names for input files and directories
"indir" is the directory containing the input files
```{r filenames and directories}

setwd("..")

indir <- "data"
rawdata <- "rawdata.csv"
column_metadata <- "column_metadata.csv"
row_metadata <- "row_metadata.csv"
subset_suffix = "group"
id_col="Collection number"


rawdatafile <- file.path(indir,rawdata)
column_metadatafile <- file.path(indir,column_metadata)
row_metadatafile <- file.path(indir,row_metadata)
```


## Documentation of data filtering and manipulation for morphological analysis

The analysis is based on three data files:
  `data/rawdata.csv`
  `data/column_metadata.csv`
  `data/row_metadata.csv`

The selection of characters for downstream analyses is based on the filtering of groups in the `data/column_metadata.csv` file.
Characters are included in a group if marked with a yes (`Y`). Then these characters are pulled in the rawdata file based on the list of selected characters in the `data/column_metadata.csv`.

```{r read rawdata, include=FALSE}

setwd("..")

dataset0<-read_csv(rawdatafile) #%>%  glimpse()
col_meta<-read_csv(column_metadatafile) #%>% glimpse() 
#List column names to select character for downstream analysis
            #"group" names correspond to the set of characters selected for a specific analysis
            #(e.g. "group1" can correspond to NMDS analysis)
row_meta<-read_csv(row_metadatafile) 
# %>%
  # glimpse()
```

# Check integrity of rawdata headings with column metadata values
Output is two lists; 
1. values which are in metadata but not in rawdata
2. values which are in rawdata but not in metadata

If no values are returned, lists match perfectly.

```{r}

## Characters in metadata without matches in dataset
col_meta$character[!col_meta$character %in% names(dataset0)]

## Characters in dataset without matches in metadata
names(dataset0)[!names(dataset0) %in% col_meta$character]
```



# Filtering of variables (characters) to use in analysis based on the column_metadata file:
Decides which columns (characters) to use,  

```{r}
include_strings=c("1","y","Y","yes","Yes")
subsetname <- "isla"
subsetcol=paste0(subsetname,"_",subset_suffix)
# include_columns = col_meta$character[unlist(col_meta[,subsetcol]) %in% include_strings]
# coltoinclude<-"isla_group"
include_columns<-filter(col_meta,.data[[subsetcol]]=="y")

# dataset_columns <- select(dataset0,all_of(include_columns))

# include_columns<-filter(col_meta,Group1=="y")
# include_columns$character
# dataset_columns <- select(dataset0,include_columns$character )
# %>%
  # glimpse()
```

## Filtering the rows of data for specific OTUs (select which samples to use)

This is from the row_metadata file.
Dataset Isla is filtering from the isla group column of the row_metadata file.
Additional columns can be added to the row_metadata file to create new groups in a similar way.
Use semi_join to keep all rows in dataset0 that match include_rows based in value of Collection number

```{r Filter_rows}

include_rows<-filter(row_meta,.data[[subsetcol]]=="Y")



# include_rows<-filter(row_meta,Islagroup=="Y")
dataset1 <- dataset0 %>% 
  select(all_of(c(id_col,include_columns$character))) %>% 
  semi_join(include_rows, by = id_col)

## Code to summarise missing data (not needed currently)
# missing.values <- dataset1 %>%
#   gather(key = "key", value = "val") %>%
#   mutate(isna = is.na(val)) %>%
#   group_by(key) %>%
#   mutate(total = n()) %>%
#   group_by(key, total, isna) %>%
#   summarise(num.isna = n()) %>%
#   mutate(pct = num.isna / total * 100) %>%
#   glimpse()

# max.miss.pct=50
# which(missing.values$pct>max.miss.pct)

missing.prop=sapply(dataset1,function(x)sum(is.na(x))/length(x))

max.miss.prop=.5
too.much.missing=which(missing.prop>max.miss.prop)

dataset1=dataset1[,-c(too.much.missing)]

# pdf("results/missing_data.pdf",width=12,height = 12)
vis_miss(dataset1)
# dev.of

# ggpairs(dataset1[,-1])
# 
# ggpairs(dataset1[,2:11])
# 
# 
# data.numeric.cor <- dataset1 %>% 
#   select(where(is.double)) %>% 
#   cor(data.numeric)
# 
# library(ggcorrplot)
# 
# 
# library(psych)
# pairs.panels(dataset1[,2:6], 
#              method = "pearson", # correlation method
#              hist.col = "#00AFBB",
#              density = TRUE,  # show density plots
#              ellipses = TRUE # show correlation ellipses
#              )

# dataset1<- dataset0 %>% semi_join(include_rows, by = id_col)
save(dataset1,file=file.path("temp",paste0("dataset_",subsetname,".rda")))
# save(dataset1,file=file.path("../temp",paste0("dataset_",subsetname,".rda")))
```





















