---
title: "Data filtering and manipulation"
author: "Shelley, Sangay and AC"
date: "02/02/2022"
output:
  pdf_document: default
  html_document: default
---
```{r}
# install.packages("knitr")
# install.packages("vegan")
# install.packages("ggplot2")
# install.packages("tidyverse")
```
*Objective:* To subset morphological data by including or excluding samples based on filters (e.g. list of characters, groupings, etc.)

*Description of script:* This is a two-step filtering processes for the downstream analysis with filtering process (1) based on the characters used and (2) based on the samples to include.

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "..")
# check and set WD for markdwon file, tools>Global options>Rmarkdown>Evaluate chunks in directory(project)
getwd()

library(cluster) #for hierarchical clustering
library(vegan) # NMDS and other statistics
library(ggplot2)
library(tidyverse)
library(GGally)
library(naniar)
library(ggcorrplot)
library(DataExplorer)

```
Define names for input files and directories
"indir" is the directory containing the input files
```{r filenames and directories}

setwd("..")

indir <- "data"
rawdata <- "rawdata.csv"
column_metadata <- "column_metadata.csv"
row_metadata <- "row_metadata.csv"
subset_suffix = "group"
id_col="Collection number"


rawdatafile <- file.path(indir,rawdata)
column_metadatafile <- file.path(indir,column_metadata)
row_metadatafile <- file.path(indir,row_metadata)
```


## Documentation of data filtering and manipulation for morphological analysis

The analysis is based on three data files:
  `data/rawdata.csv`
  `data/column_metadata.csv`
  `data/row_metadata.csv`

The selection of characters for downstream analyses is based on the filtering of groups in the `data/column_metadata.csv` file.
Characters are included in a group if marked with a yes (`Y`). Then these characters are pulled in the rawdata file based on the list of selected characters in the `data/column_metadata.csv`.

```{r read rawdata, include=FALSE}

setwd("..")

dataset0<-read_csv(rawdatafile) #%>%  glimpse()
col_meta<-read_csv(column_metadatafile) #%>% glimpse() 
#List column names to select character for downstream analysis
            #"group" names correspond to the set of characters selected for a specific analysis
            #(e.g. "group1" can correspond to NMDS analysis)
row_meta<-read_csv(row_metadatafile) 
# %>%
  # glimpse()
```

# Check integrity of rawdata headings with column metadata values
Output is two lists; 
1. values which are in metadata but not in rawdata
2. values which are in rawdata but not in metadata

If no values are returned, lists match perfectly.

```{r}

## Characters in metadata without matches in dataset
col_meta$character[!col_meta$character %in% names(dataset0)]

## Characters in dataset without matches in metadata
names(dataset0)[!names(dataset0) %in% col_meta$character]
```



# Filtering of variables (characters) to use in analysis based on the column_metadata file:
Decides which columns (characters) to use,  

```{r}
include_strings=c("1","y","Y","yes","Yes")
subsetname <- "isla"
subsetcol=paste0(subsetname,"_",subset_suffix)
# include_columns = col_meta$character[unlist(col_meta[,subsetcol]) %in% include_strings]
# coltoinclude<-"isla_group"
include_columns<-filter(col_meta,.data[[subsetcol]]=="y")

# dataset_columns <- select(dataset0,all_of(include_columns))

# include_columns<-filter(col_meta,Group1=="y")
# include_columns$character
# dataset_columns <- select(dataset0,include_columns$character )
# %>%
  # glimpse()
```

## Filtering the rows of data for specific OTUs (select which samples to use)

This is from the row_metadata file.
Dataset Isla is filtering from the isla group column of the row_metadata file.
Additional columns can be added to the row_metadata file to create new groups in a similar way.
Use semi_join to keep all rows in dataset0 that match include_rows based in value of Collection number

```{r Filter_rows}

include_rows<-filter(row_meta,.data[[subsetcol]]=="Y")

# include_rows<-filter(row_meta,Islagroup=="Y")
dataset1 <- dataset0 %>% 
  select(all_of(c(id_col,include_columns$character))) %>% 
  semi_join(include_rows, by = id_col)

## Calculate proportion of missing data
missing.prop=sapply(dataset1,function(x)sum(is.na(x))/length(x))

## Set and apply missing data threshold 
max.miss.prop=.5
too.much.missing=which(missing.prop>max.miss.prop)

dataset1=dataset1[,-c(too.much.missing)]

## Visualise missing data
vis_miss(dataset1)

## Exploratory plots using DataExplorer
## See vignette for more detailed explanations: 
##  https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html
## Broad summary
plot_intro(dataset1) 
## Barplots - should show only discrete variables
plot_bar(dataset1[,-1]) 
## Histograms - should show only continuous variables
##  - may not vary much in height with few samples, but pattern of bars
##    should allow any worrying distributions to be spotted
plot_histogram(dataset1)
## Quantile-quantile plots are  way to visualize the deviation from a specific
##  probability distribution - normal by default
plot_qq(dataset1)
## Plot correlation heatmap - probably needs finessing
plot_correlation(na.omit(dataset1))
## Plot all vs the first variable - doesn't seem to like name with spaces
##  or semicolons
dataset1_rename=dataset1%>%
  select(where(is.double))
names(dataset1_rename)=gsub(" ","_",names(dataset1_rename),fixed = T)
names(dataset1_rename)=gsub(";","",names(dataset1_rename),fixed = T)
plot_scatterplot(dataset1_rename,by = names(dataset1_rename[,2]))


## Calculate Pearson correlation coefficients and create heatmap (not using DataExplorer)
data.numeric.cor <- dataset1 %>%
  select(where(is.double)) %>%
  cor(data.numeric,use="pairwise.complete.obs") #%>% 
  round(digits = 1)

ggcorrplot(data.numeric.cor,tl.cex = 6)

 
## Scatterplot matrix in psych package only works for smaller numbers of variables
## Tried adjusting margins, with no success
# library(psych)
# opar=par()
# graphics.off()
# pdf("results/scatterplot_matrix.pdf",width=100,height=100)
# par(mai=c(1,1,1,1))
# pairs.panels(dataset1,
#              method = "pearson", # correlation method
#              hist.col = "#00AFBB",
#              density = TRUE,  # show density plots
#              ellipses = TRUE # show correlation ellipses
#              )
# dev.off()
# par(opar)


## Save dataset as Rdata file, assuming working directory is project root:
save(dataset1,file=file.path("temp",paste0("dataset_",subsetname,".rda")))
## works if wd is script directory:
# save(dataset1,file=file.path("../temp",paste0("dataset_",subsetname,".rda")))
```





















